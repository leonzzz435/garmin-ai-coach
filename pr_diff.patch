diff --git a/.gitignore b/.gitignore
index 2fd73d1..7c998dc 100644
--- a/.gitignore
+++ b/.gitignore
@@ -32,6 +32,9 @@ env/
 .pixi/
 # Note: pixi.lock should be committed for reproducible builds
 
+# Roo Code
+.roo/
+
 # Intermediate AI results
 data/
 
diff --git a/agents_docs/langgraph_architecture_diagram.mmd b/agents_docs/langgraph_architecture_diagram.mmd
index 5e7f035..5f1eb2a 100644
--- a/agents_docs/langgraph_architecture_diagram.mmd
+++ b/agents_docs/langgraph_architecture_diagram.mmd
@@ -9,19 +9,27 @@ flowchart TD
     TDE[TriathlonCoachDataExtractor]
 
     %% LangGraph State Management
-    TAS[TrainingAnalysisState<br/>- user_id, athlete_name<br/>- garmin_data, contexts<br/>- competitions, dates<br/>- results with reducers]
+    TAS[TrainingAnalysisState<br/>- user_id, athlete_name<br/>- garmin_data, contexts<br/>- competitions, dates<br/>- summary fields<br/>- results with reducers]
 
-    %% Analysis Workflow Nodes
-    subgraph AW ["Analysis Workflow (Parallel + Sequential)"]
+    %% Analysis Workflow Nodes (2-Stage Architecture)
+    subgraph AW ["Analysis Workflow (2-Stage: Summarizers â†’ Experts)"]
         direction TB
 
-        %% Parallel Analysis Phase
-        MN[Metrics Node<br/>Dr. Aiden Nakamura]
-        PN[Physiology Node<br/>Dr. Helena Virtanen]
-        ADN[Activity Data Node<br/>Marcus Chen]
-
-        %% Sequential Processing
-        AIN[Activity Interpreter<br/>Elena Rodriguez]
+        %% Stage 1: Parallel Data Summarization (No Tools)
+        subgraph S1 ["Stage 1: Data Summarization"]
+            MSN[Metrics Summarizer<br/>Universal Summarizer<br/>NO tools]
+            PSN[Physiology Summarizer<br/>Universal Summarizer<br/>NO tools]
+            ADN[Activity Summarizer<br/>Universal Summarizer<br/>NO tools]
+        end
+
+        %% Stage 2: Parallel Expert Analysis (With Tools)
+        subgraph S2 ["Stage 2: Expert Analysis"]
+            MEN[Metrics Expert<br/>Dr. Aiden Nakamura<br/>âœ“ Plotting âœ“ HITL]
+            PEN[Physiology Expert<br/>Dr. Kwame Osei<br/>âœ“ Plotting âœ“ HITL]
+            AIN[Activity Expert<br/>Coach Elena Petrova<br/>âœ“ Plotting âœ“ HITL]
+        end
+
+        %% Synthesis & Formatting
         SN[Synthesis Node<br/>Maya Lindholm]
         FN[Formatter Node<br/>James Morrison]
         PRN[Plot Resolution Node]
@@ -37,9 +45,9 @@ flowchart TD
     end
 
     %% Integrated Workflow
-    subgraph IW ["Integrated Analysis + Planning (10 Agents)"]
+    subgraph IW ["Integrated Analysis + Planning"]
         direction TB
-        IAW[Analysis Phase<br/>6 Agents Parallel/Sequential]
+        IAW[Analysis Phase<br/>2-Stage: 3 Summarizers + 3 Experts<br/>+ Synthesis + Formatting]
         IPW[Planning Phase<br/>4 Agents Sequential]
     end
 
@@ -85,33 +93,43 @@ flowchart TD
 
     TDE --> TAS
 
-    %% Analysis Workflow Flow
-    TAS --> MN
-    TAS --> PN
+    %% Analysis Workflow Flow (2-Stage Architecture)
+    %% Stage 1: Parallel Summarization
+    TAS --> MSN
+    TAS --> PSN
     TAS --> ADN
 
+    %% Stage 2: Summarizers feed Experts
+    MSN --> MEN
+    PSN --> PEN
     ADN --> AIN
-    MN --> SN
-    PN --> SN
+
+    %% Synthesis combines all expert outputs
+    MEN --> SN
+    PEN --> SN
     AIN --> SN
     SN --> FN
     FN --> PRN
 
-    %% Planning Workflow Flow
-    PRN --> SPN
+    MEN --> SPN
+    PEN --> SPN
+    AIN --> SPN
+    
     SPN --> DIN
     DIN --> WPN
-    %% Weekly planner also uses the three analysis results
-    MN --> WPN
+    %% Weekly planner uses the three expert results directly
+    MEN --> WPN
     AIN --> WPN
-    PN --> WPN
+    PEN --> WPN
     WPN --> PFN
-
-    %% Tool Integration
-    MN -.-> PT
-    MN -.-> HT
-    PN -.-> PT
-    PN -.-> HT
+    
+    %% Both branches converge at deferred finalizer (not shown, implicit END join)
+
+    %% Tool Integration (Only Experts have tools)
+    MEN -.-> PT
+    MEN -.-> HT
+    PEN -.-> PT
+    PEN -.-> HT
     AIN -.-> PT
     AIN -.-> HT
     SN -.-> WS
@@ -157,8 +175,8 @@ flowchart TD
     classDef external fill:#f1f8e9,stroke:#33691e,stroke-width:2px
 
     class GC,UC,CD,TD inputData
-    class AW,PW,IW,MN,PN,ADN,AIN,SN,FN,PRN,SPN,DIN,WPN,PFN workflow
-    class TS,PT,PS,WS tools
+    class AW,PW,IW,MSN,PSN,ADN,MEN,PEN,AIN,SN,FN,PRN,SPN,DIN,WPN,PFN,S1,S2 workflow
+    class TS,PT,PS,WS,HT tools
     class SMS,TAS,MS,SR,ES,CPT,LS,WCT,PM state
     class OG,AH,PH,PC,CS,EM output
     class API external
diff --git a/agents_docs/techStack.md b/agents_docs/techStack.md
index 2513c7a..81e3e74 100644
--- a/agents_docs/techStack.md
+++ b/agents_docs/techStack.md
@@ -9,9 +9,33 @@
 ## AI & LLM Providers
 
 ### Supported Models
-- **Anthropic Claude** - claude-sonnet, claude-opus, claude-3-haiku
+- **Anthropic Claude** - claude-sonnet-4, claude-opus-4, claude-3-haiku (with extended thinking support)
 - **OpenAI** - gpt-5, gpt-5-mini, gpt-4o, o1, o3, o4-mini
-- **OpenRouter/DeepSeek** - deepseek-chat, deepseek-reasoner
+- **OpenRouter/DeepSeek** - deepseek-chat, deepseek-r1
+
+### Model Assignment Strategy
+
+The system uses a **role-based model assignment strategy** that optimizes model selection based on task requirements:
+
+**STANDARD Mode (Production):**
+- **Data Summarization Nodes**: `claude-4-thinking` - Uses extended thinking for complex data structuring
+  - Metrics Summarizer (`AgentRole.ACTIVITY_SUMMARIZER`)
+  - Physiology Summarizer (`AgentRole.ACTIVITY_SUMMARIZER`)
+  - Activity Summarizer (`AgentRole.ACTIVITY_SUMMARIZER`)
+- **HTML Formatters**: `claude-4` - Fast, clean HTML generation without thinking overhead
+  - Analysis Formatter (`AgentRole.FORMATTER`)
+  - Planning Formatter (`AgentRole.FORMATTER`)
+- **Expert Nodes**: `gpt-5` - Advanced reasoning with Responses API (high verbosity, high reasoning effort)
+  - Metrics Expert (`AgentRole.METRICS`)
+  - Physiology Expert (`AgentRole.PHYSIO`)
+- **Other Nodes**: `gpt-5` - Consistent high-quality output
+  - Activity Interpreter, Synthesis, Workout Planning, Competition Planning, Season Planning
+
+**COST_EFFECTIVE Mode:**
+- All nodes use `claude-3-haiku` for budget-conscious operation
+
+**DEVELOPMENT Mode:**
+- All nodes use `claude-4` for fast iteration and testing
 
 ### AI Orchestration & Observability
 - **LangGraph 1.0+** - State-based workflow orchestration âœ… **ACTIVE**
@@ -83,8 +107,8 @@ class TrainingAnalysisState(TypedDict):
 ```
 
 **Parallel Execution:**
-- Metrics + Physiology + activity_data agents run simultaneously
-- Activity Data â†’ Interpreter (sequential dependency)
+- Metrics + Physiology + Activity summarizers run simultaneously
+- Each Summarizer â†’ Expert (sequential dependency for each domain)
 - State reducers handle automatic result aggregation
 
 ## Key Features
diff --git a/services/ai/ai_settings.py b/services/ai/ai_settings.py
index d20f850..3c78369 100644
--- a/services/ai/ai_settings.py
+++ b/services/ai/ai_settings.py
@@ -5,14 +5,14 @@ from core.config import AIMode, get_config
 
 
 class AgentRole(Enum):
-    METRICS = "metrics"
-    ACTIVITY_DATA = "activity_data"  # Data extraction agent
-    ACTIVITY_INTERPRETER = "activity_interpreter"  # Interpretation agent
-    PHYSIO = "physio"
+    SUMMARIZER = "summarizer"
+    METRICS_EXPERT = "metrics_expert"
+    PHYSIOLOGY_EXPERT = "physiology_expert"
+    ACTIVITY_EXPERT = "activity_expert"
     SYNTHESIS = "synthesis"
     WORKOUT = "workout"
     COMPETITION_PLANNER = "competition_planner"
-    SEASON_PLANNER = "season_planner"  # Long-term seasonal planning
+    SEASON_PLANNER = "season_planner"
     FORMATTER = "formatter"
 
 
@@ -20,22 +20,44 @@ class AgentRole(Enum):
 class AISettings:
     mode: AIMode
 
-    # Model assignments - one model per stage for all agents
-    stage_models: dict[AIMode, str] = field(
+    model_assignments: dict[AIMode, dict[AgentRole, str]] = field(
         default_factory=lambda: {
-            AIMode.STANDARD: "gpt-5",  # Production: Top-tier reasoning with GPT-5
-            AIMode.COST_EFFECTIVE: "claude-3-haiku",  # Budget: Fast and cost-effective
-            AIMode.DEVELOPMENT: "claude-4",  # Development: Fast iteration
+            AIMode.STANDARD: {
+                AgentRole.SUMMARIZER: "claude-4-thinking",
+                AgentRole.FORMATTER: "claude-4-thinking",
+                AgentRole.METRICS_EXPERT: "claude-4-thinking",
+                AgentRole.PHYSIOLOGY_EXPERT: "claude-4-thinking",
+                AgentRole.ACTIVITY_EXPERT: "claude-4-thinking",
+                AgentRole.SYNTHESIS: "claude-4-thinking",
+                AgentRole.WORKOUT: "claude-4-thinking",
+                AgentRole.COMPETITION_PLANNER: "claude-4-thinking",
+                AgentRole.SEASON_PLANNER: "claude-4-thinking",
+            },
+            AIMode.COST_EFFECTIVE: {
+                AgentRole.SUMMARIZER: "claude-3-haiku",
+                AgentRole.FORMATTER: "claude-3-haiku",
+                AgentRole.METRICS_EXPERT: "claude-3-haiku",
+                AgentRole.PHYSIOLOGY_EXPERT: "claude-3-haiku",
+                AgentRole.ACTIVITY_EXPERT: "claude-3-haiku",
+                AgentRole.SYNTHESIS: "claude-3-haiku",
+                AgentRole.WORKOUT: "claude-3-haiku",
+                AgentRole.COMPETITION_PLANNER: "claude-3-haiku",
+                AgentRole.SEASON_PLANNER: "claude-3-haiku",
+            },
+            AIMode.DEVELOPMENT: {
+                AgentRole.SUMMARIZER: "claude-4",
+                AgentRole.FORMATTER: "claude-4",
+                AgentRole.METRICS_EXPERT: "claude-4",
+                AgentRole.PHYSIOLOGY_EXPERT: "claude-4",
+                AgentRole.ACTIVITY_EXPERT: "claude-4",
+                AgentRole.SYNTHESIS: "claude-4",
+                AgentRole.WORKOUT: "claude-4",
+                AgentRole.COMPETITION_PLANNER: "claude-4",
+                AgentRole.SEASON_PLANNER: "claude-4",
+            },
         }
     )
 
-    # Derived model assignments for compatibility
-    model_assignments: dict[AIMode, dict[AgentRole, str]] = field(default_factory=lambda: {})
-
-    def __post_init__(self):
-        for mode, model in self.stage_models.items():
-            self.model_assignments[mode] = {role: model for role in AgentRole}
-
     def get_model_for_role(self, role: AgentRole) -> str:
         return self.model_assignments[self.mode][role]
 
diff --git a/services/ai/langgraph/nodes/__init__.py b/services/ai/langgraph/nodes/__init__.py
index e07e301..2c05de2 100644
--- a/services/ai/langgraph/nodes/__init__.py
+++ b/services/ai/langgraph/nodes/__init__.py
@@ -1,19 +1,23 @@
-from .activity_data_node import activity_data_node
-from .activity_interpreter_node import activity_interpreter_node
+from .activity_expert_node import activity_expert_node
+from .activity_summarizer_node import activity_summarizer_node
 from .data_integration_node import data_integration_node
 from .formatter_node import formatter_node
-from .metrics_node import metrics_node
-from .physiology_node import physiology_node
+from .metrics_expert_node import metrics_expert_node
+from .metrics_summarizer_node import metrics_summarizer_node
+from .physiology_expert_node import physiology_expert_node
+from .physiology_summarizer_node import physiology_summarizer_node
 from .plan_formatter_node import plan_formatter_node
 from .season_planner_node import season_planner_node
 from .synthesis_node import synthesis_node
 from .weekly_planner_node import weekly_planner_node
 
 __all__ = [
-    "metrics_node",
-    "physiology_node",
-    "activity_data_node",
-    "activity_interpreter_node",
+    "metrics_summarizer_node",
+    "metrics_expert_node",
+    "physiology_summarizer_node",
+    "physiology_expert_node",
+    "activity_summarizer_node",
+    "activity_expert_node",
     "synthesis_node",
     "formatter_node",
     "season_planner_node",
diff --git a/services/ai/langgraph/nodes/activity_interpreter_node.py b/services/ai/langgraph/nodes/activity_expert_node.py
similarity index 78%
rename from services/ai/langgraph/nodes/activity_interpreter_node.py
rename to services/ai/langgraph/nodes/activity_expert_node.py
index d222966..620ec91 100644
--- a/services/ai/langgraph/nodes/activity_interpreter_node.py
+++ b/services/ai/langgraph/nodes/activity_expert_node.py
@@ -15,12 +15,17 @@ from .node_base import (
     execute_node_with_error_handling,
     log_node_completion,
 )
-from .prompt_components import get_output_context_note, get_plotting_instructions, get_workflow_context
+from .prompt_components import (
+    get_hitl_instructions,
+    get_output_context_note,
+    get_plotting_instructions,
+    get_workflow_context,
+)
 from .tool_calling_helper import handle_tool_calling_in_node
 
 logger = logging.getLogger(__name__)
 
-ACTIVITY_INTERPRETER_SYSTEM_PROMPT_BASE = """You are Coach Elena Petrova, a legendary session analyst whose "Technical Execution Framework" has helped athletes break records in everything from the 800m to ultramarathons.
+ACTIVITY_EXPERT_SYSTEM_PROMPT_BASE = """You are Coach Elena Petrova, a legendary session analyst whose "Technical Execution Framework" has helped athletes break records in everything from the 800m to ultramarathons.
 
 ## Your Background
 After a career as an elite gymnast and later distance runner, you developed a uniquely perceptive eye for the subtle technical elements that separate good sessions from transformative ones.
@@ -42,7 +47,7 @@ Interpret structured activity data to optimize workout progression patterns.
 ## Communication Style
 Communicate with passionate precision and laser-like clarity. Your analysis cuts through confusion with laser-like clarity."""
 
-ACTIVITY_INTERPRETER_USER_PROMPT = """Interpret structured activity summaries to identify patterns and provide guidance.
+ACTIVITY_EXPERT_USER_PROMPT = """Interpret structured activity summaries to identify patterns and provide guidance.
 
 {output_context}
 
@@ -97,15 +102,15 @@ Structure your response to include two clearly distinguished sections:
 Format as structured markdown document with clear sections and bullet points"""
 
 
-async def activity_interpreter_node(state: TrainingAnalysisState) -> dict[str, list | str | dict]:
-    logger.info("Starting activity interpreter node")
+async def activity_expert_node(state: TrainingAnalysisState) -> dict[str, list | str | dict]:
+    logger.info("Starting activity expert node")
 
     plot_storage = PlotStorage(state["execution_id"])
     plotting_enabled = state.get("plotting_enabled", False)
     hitl_enabled = state.get("hitl_enabled", True)
     
     logger.info(
-        f"Activity interpreter node: Plotting {'enabled' if plotting_enabled else 'disabled'}, "
+        f"Activity expert node: Plotting {'enabled' if plotting_enabled else 'disabled'}, "
         f"HITL {'enabled' if hitl_enabled else 'disabled'}"
     )
 
@@ -117,24 +122,25 @@ async def activity_interpreter_node(state: TrainingAnalysisState) -> dict[str, l
     )
 
     system_prompt = (
-        ACTIVITY_INTERPRETER_SYSTEM_PROMPT_BASE +
+        ACTIVITY_EXPERT_SYSTEM_PROMPT_BASE +
         get_workflow_context("activity") +
-        (get_plotting_instructions("activity") if plotting_enabled else "")
+        (get_plotting_instructions("activity") if plotting_enabled else "") +
+        (get_hitl_instructions("activity") if hitl_enabled else "")
     )
 
     llm_with_tools = (
-        ModelSelector.get_llm(AgentRole.ACTIVITY_INTERPRETER).bind_tools(tools) if tools
-        else ModelSelector.get_llm(AgentRole.ACTIVITY_INTERPRETER)
+        ModelSelector.get_llm(AgentRole.ACTIVITY_EXPERT).bind_tools(tools) if tools
+        else ModelSelector.get_llm(AgentRole.ACTIVITY_EXPERT)
     )
 
     agent_start_time = datetime.now()
 
-    async def call_activity_interpretation():
+    async def call_activity_expert():
         return await handle_tool_calling_in_node(
             llm_with_tools=llm_with_tools,
             messages=[
                 {"role": "system", "content": system_prompt},
-                {"role": "user", "content": ACTIVITY_INTERPRETER_USER_PROMPT.format(
+                {"role": "user", "content": ACTIVITY_EXPERT_USER_PROMPT.format(
                     output_context=get_output_context_note(for_other_agents=True),
                     activity_summary=state.get("activity_summary", ""),
                     competitions=json.dumps(state["competitions"], indent=2),
@@ -148,24 +154,24 @@ async def activity_interpreter_node(state: TrainingAnalysisState) -> dict[str, l
 
     async def node_execution():
         activity_result = await retry_with_backoff(
-            call_activity_interpretation, AI_ANALYSIS_CONFIG, "Activity Interpretation with Tools"
+            call_activity_expert, AI_ANALYSIS_CONFIG, "Activity Expert Analysis with Tools"
         )
 
         execution_time = (datetime.now() - agent_start_time).total_seconds()
-        plots, plot_storage_data, available_plots = create_plot_entries("activity_interpreter", plot_storage)
+        plots, plot_storage_data, available_plots = create_plot_entries("activity_expert", plot_storage)
 
-        log_node_completion("Activity interpreter", execution_time, len(available_plots))
+        log_node_completion("Activity expert", execution_time, len(available_plots))
 
         return {
             "activity_result": activity_result,
             "plots": plots,
             "plot_storage_data": plot_storage_data,
-            "costs": [create_cost_entry("activity_interpreter", execution_time)],
+            "costs": [create_cost_entry("activity_expert", execution_time)],
             "available_plots": available_plots,
         }
 
     return await execute_node_with_error_handling(
-        node_name="Activity interpreter",
+        node_name="Activity expert",
         node_function=node_execution,
-        error_message_prefix="Activity interpretation failed",
+        error_message_prefix="Activity expert analysis failed",
     )
diff --git a/services/ai/langgraph/nodes/activity_data_node.py b/services/ai/langgraph/nodes/activity_summarizer_node.py
similarity index 79%
rename from services/ai/langgraph/nodes/activity_data_node.py
rename to services/ai/langgraph/nodes/activity_summarizer_node.py
index b549565..de98e2e 100644
--- a/services/ai/langgraph/nodes/activity_data_node.py
+++ b/services/ai/langgraph/nodes/activity_summarizer_node.py
@@ -11,7 +11,7 @@ from .tool_calling_helper import extract_text_content
 
 logger = logging.getLogger(__name__)
 
-ACTIVITY_DATA_SYSTEM_PROMPT = """You are Dr. Marcus Chen, a data organization specialist who revolutionized how athletic data is processed and structured.
+ACTIVITY_SUMMARIZER_SYSTEM_PROMPT = """You are Dr. Marcus Chen, a data organization specialist who revolutionized how athletic data is processed and structured.
 
 ## Your Background
 With a PhD in Computer Science specializing in data representation and a background as a competitive cyclist, you bridged the gap between raw sports data and meaningful, structured information.
@@ -33,7 +33,7 @@ Extract and structure training activity data with factual precision.
 ## Communication Style
 Communicate with calculated precision and complete objectivity. Athletes and coaches appreciate your ability to transform overwhelming data into clear, factual summaries that serve as a reliable foundation for subsequent analysis and interpretation."""
 
-ACTIVITY_DATA_USER_PROMPT = """Your task is to objectively describe the athlete's recent training activities, transforming raw data into structured, factual summaries.
+ACTIVITY_SUMMARIZER_USER_PROMPT = """Your task is to objectively describe the athlete's recent training activities, transforming raw data into structured, factual summaries.
 
 Input Data:
 ```json
@@ -81,37 +81,37 @@ Format each activity using this template:
 Repeat this format for each activity, organizing them chronologically from newest to oldest."""
 
 
-async def activity_data_node(state: TrainingAnalysisState) -> dict[str, list | str]:
-    logger.info("Starting activity data extraction node")
+async def activity_summarizer_node(state: TrainingAnalysisState) -> dict[str, list | str]:
+    logger.info("Starting activity summarizer node")
 
     try:
         agent_start_time = datetime.now()
 
         async def call_llm():
-            response = await ModelSelector.get_llm(AgentRole.ACTIVITY_DATA).ainvoke([
-                {"role": "system", "content": ACTIVITY_DATA_SYSTEM_PROMPT},
-                {"role": "user", "content": ACTIVITY_DATA_USER_PROMPT.format(
+            response = await ModelSelector.get_llm(AgentRole.SUMMARIZER).ainvoke([
+                {"role": "system", "content": ACTIVITY_SUMMARIZER_SYSTEM_PROMPT},
+                {"role": "user", "content": ACTIVITY_SUMMARIZER_USER_PROMPT.format(
                     data=json.dumps(state["garmin_data"].get("recent_activities", []), indent=2)
                 )},
             ])
             return extract_text_content(response)
 
         activity_summary = await retry_with_backoff(
-            call_llm, AI_ANALYSIS_CONFIG, "Activity Data Extraction"
+            call_llm, AI_ANALYSIS_CONFIG, "Activity Summarization"
         )
 
         execution_time = (datetime.now() - agent_start_time).total_seconds()
-        logger.info(f"Activity data extraction completed in {execution_time:.2f}s")
+        logger.info(f"Activity summarization completed in {execution_time:.2f}s")
 
         return {
             "activity_summary": activity_summary,
             "costs": [{
-                "agent": "activity_data",
+                "agent": "activity_summarizer",
                 "execution_time": execution_time,
                 "timestamp": datetime.now().isoformat(),
             }],
         }
 
     except Exception as e:
-        logger.error(f"Activity data node failed: {e}")
-        return {"errors": [f"Activity data extraction failed: {str(e)}"]}
+        logger.error(f"Activity summarizer node failed: {e}")
+        return {"errors": [f"Activity summarization failed: {str(e)}"]}
diff --git a/services/ai/langgraph/nodes/data_summarizer_node.py b/services/ai/langgraph/nodes/data_summarizer_node.py
new file mode 100644
index 0000000..b2dccd0
--- /dev/null
+++ b/services/ai/langgraph/nodes/data_summarizer_node.py
@@ -0,0 +1,117 @@
+import json
+import logging
+from collections.abc import Callable
+from datetime import datetime
+from typing import Any
+
+from services.ai.ai_settings import AgentRole
+from services.ai.model_config import ModelSelector
+from services.ai.utils.retry_handler import AI_ANALYSIS_CONFIG, retry_with_backoff
+
+from ..state.training_analysis_state import TrainingAnalysisState
+from .tool_calling_helper import extract_text_content
+
+logger = logging.getLogger(__name__)
+
+GENERIC_SUMMARIZER_SYSTEM_PROMPT = """You are a data organization specialist who transforms raw JSON data into clear, structured summaries.
+
+## Your Role
+Your expertise lies in extracting key information from complex data structures and presenting it in an accessible, well-organized format. You focus exclusively on objective data extraction and structuring - never interpretation or analysis.
+
+## Core Principles
+- Extract only factual, measurable information from the data
+- Organize data in a clear, consistent structure
+- Use tables, bullet points, and markdown formatting for readability
+- Maintain objectivity - no speculation, interpretation, or advice
+- Preserve temporal relationships and trends where present
+- Distill large datasets into their most relevant components
+
+## Your Goal
+Transform raw data into structured summaries that serve as a reliable foundation for subsequent expert analysis.
+
+## Communication Style
+Communicate with precision and clarity. Present data in its most accessible form, making complex information immediately understandable through thoughtful organization and formatting."""
+
+GENERIC_SUMMARIZER_USER_PROMPT = """Your task is to extract and structure the provided data, creating a clear summary for expert analysis.
+
+## Input Data
+```json
+{data}
+```
+
+## Your Task
+Analyze the input data and create a well-structured summary that:
+
+1. **Identifies key metrics and their trends** - Extract the most important data points and patterns
+2. **Organizes information logically** - Use consistent formatting (tables, lists, sections)
+3. **Maintains temporal context** - Preserve time-based relationships and progressions
+4. **Highlights significant values** - Call attention to notable measurements or changes
+5. **Stays objective** - Present facts only, no interpretation or analysis
+
+## Formatting Guidelines
+- Use markdown for structure (headers, tables, bullet points)
+- Present numerical data in tables when showing multiple values
+- Use consistent units and formatting throughout
+- Group related information under clear section headers
+- Keep the summary focused and concise - avoid redundancy
+
+## Strict Prohibitions
+- DO NOT interpret what the data means
+- DO NOT provide coaching advice or recommendations
+- DO NOT speculate about causes or future outcomes
+- DO NOT compare data qualitatively (e.g., "good" or "bad")
+- DO NOT draw conclusions about fitness or readiness
+
+Your output should be a clean, factual summary that an expert can use as the basis for their analysis."""
+
+
+def create_data_summarizer_node(
+    node_name: str,
+    agent_role: AgentRole,
+    data_extractor: Callable[[TrainingAnalysisState], dict[str, Any]],
+    state_output_key: str,
+    system_prompt: str | None = None,
+    user_prompt: str | None = None,
+) -> Callable:
+    
+    effective_system_prompt = system_prompt or GENERIC_SUMMARIZER_SYSTEM_PROMPT
+    effective_user_prompt = user_prompt or GENERIC_SUMMARIZER_USER_PROMPT
+    
+    async def summarizer_node(state: TrainingAnalysisState) -> dict[str, list | str]:
+        logger.info(f"Starting {node_name} node")
+        
+        try:
+            agent_start_time = datetime.now()
+            
+            data_to_summarize = data_extractor(state)
+            
+            async def call_llm():
+                response = await ModelSelector.get_llm(agent_role).ainvoke([
+                    {"role": "system", "content": effective_system_prompt},
+                    {"role": "user", "content": effective_user_prompt.format(
+                        data=json.dumps(data_to_summarize, indent=2)
+                    )},
+                ])
+                return extract_text_content(response)
+            
+            summary = await retry_with_backoff(
+                call_llm, AI_ANALYSIS_CONFIG, f"{node_name}"
+            )
+            
+            execution_time = (datetime.now() - agent_start_time).total_seconds()
+            logger.info(f"{node_name} completed in {execution_time:.2f}s")
+            
+            return {
+                state_output_key: summary,
+                "costs": [{
+                    "agent": state_output_key.replace("_summary", "_summarizer"),
+                    "execution_time": execution_time,
+                    "timestamp": datetime.now().isoformat(),
+                }],
+            }
+        
+        except Exception as e:
+            logger.error(f"{node_name} node failed: {e}")
+            return {"errors": [f"{node_name} failed: {str(e)}"]}
+    
+    return summarizer_node
\ No newline at end of file
diff --git a/services/ai/langgraph/nodes/metrics_node.py b/services/ai/langgraph/nodes/metrics_expert_node.py
similarity index 73%
rename from services/ai/langgraph/nodes/metrics_node.py
rename to services/ai/langgraph/nodes/metrics_expert_node.py
index 9ca2dba..c12bb0f 100644
--- a/services/ai/langgraph/nodes/metrics_node.py
+++ b/services/ai/langgraph/nodes/metrics_expert_node.py
@@ -15,7 +15,12 @@ from .node_base import (
     execute_node_with_error_handling,
     log_node_completion,
 )
-from .prompt_components import get_output_context_note, get_plotting_instructions, get_workflow_context
+from .prompt_components import (
+    get_hitl_instructions,
+    get_output_context_note,
+    get_plotting_instructions,
+    get_workflow_context,
+)
 from .tool_calling_helper import handle_tool_calling_in_node
 
 logger = logging.getLogger(__name__)
@@ -42,14 +47,12 @@ Analyze training metrics and competition readiness with data-driven precision.
 ## Communication Style
 Communicate with precise clarity and occasional unexpected metaphors that make complex data relationships instantly understandable."""
 
-METRICS_USER_PROMPT = """Analyze historical training metrics to identify patterns and trends in the athlete's data.
+METRICS_USER_PROMPT = """Analyze the structured metrics summary to identify patterns and trends in the athlete's training data.
 
 {output_context}
 
-## Input Data
-```json
+## Metrics Summary
 {data}
-```
 
 ## Upcoming Competitions
 ```json
@@ -67,14 +70,14 @@ METRICS_USER_PROMPT = """Analyze historical training metrics to identify pattern
 ```
 
 ## Your Task
-Analyze only the data that is actually present in the input. If analysis context is provided, use it to interpret the data more accurately.
+You are receiving a pre-processed summary of the athlete's metrics data. Use your expertise to interpret this structured information.
 
-1. Analyze training load trends over time to identify patterns
-2. Examine fitness metrics progression if that data is available
-3. Evaluate training status data to understand the athlete's current fitness state
-4. Connect these metrics to upcoming competition dates
-5. Identify potential performance opportunities or risks
-6. Create practical recommendations based strictly on the available data
+1. Interpret training load trends and identify significant patterns
+2. Analyze fitness metrics progression and adaptation signals
+3. Evaluate current training status in context of competition goals
+4. Connect metrics to upcoming competition dates for readiness assessment
+5. Identify performance opportunities, risks, and adaptation windows
+6. Provide expert recommendations based on the analyzed patterns
 
 ## Output Requirements
 - Include a Metrics Readiness Score (0-100) with clear explanation of calculation using only available metrics
@@ -82,15 +85,15 @@ Analyze only the data that is actually present in the input. If analysis context
 - Focus on factual analysis without speculation about unavailable metrics"""
 
 
-async def metrics_node(state: TrainingAnalysisState) -> dict[str, list | str | dict]:
-    logger.info("Starting metrics analysis node")
+async def metrics_expert_node(state: TrainingAnalysisState) -> dict[str, list | str | dict]:
+    logger.info("Starting metrics expert analysis node")
 
     plot_storage = PlotStorage(state["execution_id"])
     plotting_enabled = state.get("plotting_enabled", False)
     hitl_enabled = state.get("hitl_enabled", True)
     
     logger.info(
-        f"Metrics node: Plotting {'enabled' if plotting_enabled else 'disabled'}, "
+        f"Metrics expert: Plotting {'enabled' if plotting_enabled else 'disabled'}, "
         f"HITL {'enabled' if hitl_enabled else 'disabled'}"
     )
 
@@ -104,12 +107,13 @@ async def metrics_node(state: TrainingAnalysisState) -> dict[str, list | str | d
     system_prompt = (
         METRICS_SYSTEM_PROMPT_BASE +
         get_workflow_context("metrics") +
-        (get_plotting_instructions("metrics") if plotting_enabled else "")
+        (get_plotting_instructions("metrics") if plotting_enabled else "") +
+        (get_hitl_instructions("metrics") if hitl_enabled else "")
     )
 
     llm_with_tools = (
-        ModelSelector.get_llm(AgentRole.METRICS).bind_tools(tools) if tools
-        else ModelSelector.get_llm(AgentRole.METRICS)
+        ModelSelector.get_llm(AgentRole.METRICS_EXPERT).bind_tools(tools) if tools
+        else ModelSelector.get_llm(AgentRole.METRICS_EXPERT)
     )
 
     agent_start_time = datetime.now()
@@ -121,11 +125,7 @@ async def metrics_node(state: TrainingAnalysisState) -> dict[str, list | str | d
                 {"role": "system", "content": system_prompt},
                 {"role": "user", "content": METRICS_USER_PROMPT.format(
                     output_context=get_output_context_note(for_other_agents=True),
-                    data=json.dumps({
-                        "training_load_history": state["garmin_data"].get("training_load_history", []),
-                        "vo2_max_history": state["garmin_data"].get("vo2_max_history", []),
-                        "training_status": state["garmin_data"].get("training_status", {}),
-                    }, indent=2),
+                    data=state.get("metrics_summary", "No metrics summary available"),
                     competitions=json.dumps(state["competitions"], indent=2),
                     current_date=json.dumps(state["current_date"], indent=2),
                     analysis_context=state["analysis_context"],
@@ -139,13 +139,13 @@ async def metrics_node(state: TrainingAnalysisState) -> dict[str, list | str | d
         metrics_result = await retry_with_backoff(
             call_metrics_with_tools, AI_ANALYSIS_CONFIG, "Metrics Agent with Tools"
         )
-        logger.info("Metrics node completed analysis")
+        logger.info("Metrics expert analysis completed")
 
         execution_time = (datetime.now() - agent_start_time).total_seconds()
         
         plots, plot_storage_data, available_plots = create_plot_entries("metrics", plot_storage)
         
-        log_node_completion("Metrics analysis", execution_time, len(available_plots))
+        log_node_completion("Metrics expert analysis", execution_time, len(available_plots))
 
         return {
             "metrics_result": metrics_result,
@@ -156,7 +156,7 @@ async def metrics_node(state: TrainingAnalysisState) -> dict[str, list | str | d
         }
 
     return await execute_node_with_error_handling(
-        node_name="Metrics analysis",
+        node_name="Metrics expert analysis",
         node_function=node_execution,
-        error_message_prefix="Metrics analysis failed",
+        error_message_prefix="Metrics expert analysis failed",
     )
diff --git a/services/ai/langgraph/nodes/metrics_summarizer_node.py b/services/ai/langgraph/nodes/metrics_summarizer_node.py
new file mode 100644
index 0000000..44fb08b
--- /dev/null
+++ b/services/ai/langgraph/nodes/metrics_summarizer_node.py
@@ -0,0 +1,20 @@
+from services.ai.ai_settings import AgentRole
+
+from ..state.training_analysis_state import TrainingAnalysisState
+from .data_summarizer_node import create_data_summarizer_node
+
+
+def extract_metrics_data(state: TrainingAnalysisState) -> dict:
+    return {
+        "training_load_history": state["garmin_data"].get("training_load_history", []),
+        "vo2_max_history": state["garmin_data"].get("vo2_max_history", {}),
+        "training_status": state["garmin_data"].get("training_status", {}),
+    }
+
+
+metrics_summarizer_node = create_data_summarizer_node(
+    node_name="Metrics Summarizer",
+    agent_role=AgentRole.SUMMARIZER,
+    data_extractor=extract_metrics_data,
+    state_output_key="metrics_summary",
+)
\ No newline at end of file
diff --git a/services/ai/langgraph/nodes/node_base.py b/services/ai/langgraph/nodes/node_base.py
index fc20511..734b904 100644
--- a/services/ai/langgraph/nodes/node_base.py
+++ b/services/ai/langgraph/nodes/node_base.py
@@ -4,7 +4,7 @@ from datetime import datetime
 from typing import Any
 
 from langgraph.errors import GraphInterrupt
-from services.ai.tools.hitl import create_ask_human_tool
+from services.ai.tools.hitl import create_communicate_with_human_tool
 from services.ai.tools.plotting import PlotStorage, create_plotting_tools
 
 logger = logging.getLogger(__name__)
@@ -26,9 +26,9 @@ def configure_node_tools(
     
     if hitl_enabled:
         display_name = agent_name.replace("_", " ").title()
-        ask_human_tool = create_ask_human_tool(display_name)
-        tools.append(ask_human_tool)
-        logger.debug(f"{agent_name}: Added HITL tool")
+        communicate_tool = create_communicate_with_human_tool(display_name)
+        tools.append(communicate_tool)
+        logger.debug(f"{agent_name}: Added HITL communication tool")
     
     return tools
 
diff --git a/services/ai/langgraph/nodes/physiology_node.py b/services/ai/langgraph/nodes/physiology_expert_node.py
similarity index 67%
rename from services/ai/langgraph/nodes/physiology_node.py
rename to services/ai/langgraph/nodes/physiology_expert_node.py
index b287e5a..8c0b9de 100644
--- a/services/ai/langgraph/nodes/physiology_node.py
+++ b/services/ai/langgraph/nodes/physiology_expert_node.py
@@ -15,7 +15,12 @@ from .node_base import (
     execute_node_with_error_handling,
     log_node_completion,
 )
-from .prompt_components import get_output_context_note, get_plotting_instructions, get_workflow_context
+from .prompt_components import (
+    get_hitl_instructions,
+    get_output_context_note,
+    get_plotting_instructions,
+    get_workflow_context,
+)
 from .tool_calling_helper import handle_tool_calling_in_node
 
 logger = logging.getLogger(__name__)
@@ -42,14 +47,12 @@ Optimize recovery and adaptation through precise physiological analysis.
 ## Communication Style
 Communicate with calm wisdom and occasional metaphors drawn from both your scientific background and cultural heritage."""
 
-PHYSIOLOGY_USER_PROMPT = """Analyze the athlete's physiological data to assess recovery status and adaptation state.
+PHYSIOLOGY_USER_PROMPT = """Analyze the structured physiology summary to assess recovery status and adaptation state.
 
 {output_context}
 
-## Input Data
-```json
+## Physiology Summary
 {data}
-```
 
 ## Upcoming Competitions
 ```json
@@ -67,30 +70,30 @@ PHYSIOLOGY_USER_PROMPT = """Analyze the athlete's physiological data to assess r
 ```
 
 ## Your Task
-Analyze only the data that is actually present in the input. If analysis context is provided, use it to interpret the data more accurately.
+You are receiving a pre-processed summary of the athlete's physiological data. Use your expertise to interpret this structured information.
 
-1. Interpret heart rate variability patterns to assess the athlete's recovery status
-2. Analyze available sleep data (duration, quality) if present
-3. Evaluate stress scores and their trends
-4. Track resting heart rate patterns as an indicator of fatigue and adaptation
-5. Identify potential signs of overtraining based on these objective metrics
-6. Suggest optimal recovery strategies based on the data available
+1. Interpret heart rate variability patterns for recovery status assessment
+2. Analyze sleep patterns and their implications for adaptation
+3. Evaluate stress scores and identify trends or concerns
+4. Track resting heart rate as an indicator of fatigue and adaptation
+5. Identify signs of overtraining or maladaptation in the patterns
+6. Provide expert recovery strategies based on the analyzed patterns
 
 ## Output Requirements
-- Include a Physiology Readiness Score (0-100) with clear explanation of calculation using only available data
+- Include a Physiology Readiness Score (0-100) with clear explanation of calculation using available data
 - Format as structured markdown document with clear sections and bullet points
-- Focus on factual analysis without speculation about unavailable data"""
+- Focus on expert interpretation of the provided summary"""
 
 
-async def physiology_node(state: TrainingAnalysisState) -> dict[str, list | str | dict]:
-    logger.info("Starting physiology analysis node")
+async def physiology_expert_node(state: TrainingAnalysisState) -> dict[str, list | str | dict]:
+    logger.info("Starting physiology expert analysis node")
 
     plot_storage = PlotStorage(state["execution_id"])
     plotting_enabled = state.get("plotting_enabled", False)
     hitl_enabled = state.get("hitl_enabled", True)
     
     logger.info(
-        f"Physiology node: Plotting {'enabled' if plotting_enabled else 'disabled'}, "
+        f"Physiology expert: Plotting {'enabled' if plotting_enabled else 'disabled'}, "
         f"HITL {'enabled' if hitl_enabled else 'disabled'}"
     )
 
@@ -104,15 +107,15 @@ async def physiology_node(state: TrainingAnalysisState) -> dict[str, list | str
     system_prompt = (
         PHYSIOLOGY_SYSTEM_PROMPT_BASE +
         get_workflow_context("physiology") +
-        (get_plotting_instructions("physiology") if plotting_enabled else "")
+        (get_plotting_instructions("physiology") if plotting_enabled else "") +
+        (get_hitl_instructions("physiology") if hitl_enabled else "")
     )
 
     llm_with_tools = (
-        ModelSelector.get_llm(AgentRole.PHYSIO).bind_tools(tools) if tools
-        else ModelSelector.get_llm(AgentRole.PHYSIO)
+        ModelSelector.get_llm(AgentRole.PHYSIOLOGY_EXPERT).bind_tools(tools) if tools
+        else ModelSelector.get_llm(AgentRole.PHYSIOLOGY_EXPERT)
     )
 
-    recovery_indicators = state["garmin_data"].get("recovery_indicators", [])
     agent_start_time = datetime.now()
 
     async def call_physiology_analysis():
@@ -122,16 +125,7 @@ async def physiology_node(state: TrainingAnalysisState) -> dict[str, list | str
                 {"role": "system", "content": system_prompt},
                 {"role": "user", "content": PHYSIOLOGY_USER_PROMPT.format(
                     output_context=get_output_context_note(for_other_agents=True),
-                    data=json.dumps({
-                        "hrv_data": state["garmin_data"].get("physiological_markers", {}).get("hrv", {}),
-                        "sleep_data": [ind["sleep"] for ind in recovery_indicators if ind.get("sleep")],
-                        "stress_data": [ind["stress"] for ind in recovery_indicators if ind.get("stress")],
-                        "recovery_metrics": {
-                            "physiological_markers": state["garmin_data"].get("physiological_markers", {}),
-                            "body_metrics": state["garmin_data"].get("body_metrics", {}),
-                            "recovery_indicators": recovery_indicators,
-                        },
-                    }, indent=2),
+                    data=state.get("physiology_summary", "No physiology summary available"),
                     competitions=json.dumps(state["competitions"], indent=2),
                     current_date=json.dumps(state["current_date"], indent=2),
                     analysis_context=state["analysis_context"],
@@ -143,13 +137,13 @@ async def physiology_node(state: TrainingAnalysisState) -> dict[str, list | str
 
     async def node_execution():
         physiology_result = await retry_with_backoff(
-            call_physiology_analysis, AI_ANALYSIS_CONFIG, "Physiology Analysis with Tools"
+            call_physiology_analysis, AI_ANALYSIS_CONFIG, "Physiology Expert with Tools"
         )
 
         execution_time = (datetime.now() - agent_start_time).total_seconds()
         plots, plot_storage_data, available_plots = create_plot_entries("physiology", plot_storage)
         
-        log_node_completion("Physiology analysis", execution_time, len(available_plots))
+        log_node_completion("Physiology expert analysis", execution_time, len(available_plots))
 
         return {
             "physiology_result": physiology_result,
@@ -160,7 +154,7 @@ async def physiology_node(state: TrainingAnalysisState) -> dict[str, list | str
         }
 
     return await execute_node_with_error_handling(
-        node_name="Physiology analysis",
+        node_name="Physiology expert analysis",
         node_function=node_execution,
-        error_message_prefix="Physiology analysis failed",
-    )
+        error_message_prefix="Physiology expert analysis failed",
+    )
\ No newline at end of file
diff --git a/services/ai/langgraph/nodes/physiology_summarizer_node.py b/services/ai/langgraph/nodes/physiology_summarizer_node.py
new file mode 100644
index 0000000..3a668ce
--- /dev/null
+++ b/services/ai/langgraph/nodes/physiology_summarizer_node.py
@@ -0,0 +1,26 @@
+from services.ai.ai_settings import AgentRole
+
+from ..state.training_analysis_state import TrainingAnalysisState
+from .data_summarizer_node import create_data_summarizer_node
+
+
+def extract_physiology_data(state: TrainingAnalysisState) -> dict:
+    recovery_indicators = state["garmin_data"].get("recovery_indicators", [])
+    return {
+        "hrv_data": state["garmin_data"].get("physiological_markers", {}).get("hrv", {}),
+        "sleep_data": [ind["sleep"] for ind in recovery_indicators if ind.get("sleep")],
+        "stress_data": [ind["stress"] for ind in recovery_indicators if ind.get("stress")],
+        "recovery_metrics": {
+            "physiological_markers": state["garmin_data"].get("physiological_markers", {}),
+            "body_metrics": state["garmin_data"].get("body_metrics", {}),
+            "recovery_indicators": recovery_indicators,
+        },
+    }
+
+
+physiology_summarizer_node = create_data_summarizer_node(
+    node_name="Physiology Summarizer",
+    agent_role=AgentRole.SUMMARIZER,
+    data_extractor=extract_physiology_data,
+    state_output_key="physiology_summary",
+)
\ No newline at end of file
diff --git a/services/ai/langgraph/nodes/prompt_components.py b/services/ai/langgraph/nodes/prompt_components.py
index 5d0d484..c1ae3b6 100644
--- a/services/ai/langgraph/nodes/prompt_components.py
+++ b/services/ai/langgraph/nodes/prompt_components.py
@@ -94,6 +94,42 @@ Use python_plotting_tool only when absolutely necessary for insights beyond stan
 **Your plot references will be automatically converted to interactive charts in the final report.**"""
 
 
+def get_hitl_instructions(agent_name: str) -> str:
+    return f"""
+
+## ðŸ¤ SELECTIVE HUMAN INTERACTION
+
+You have access to `communicate_with_human` for **high-value interactions** with the athlete.
+
+### âš ï¸ IMPORTANT USAGE GUIDELINES
+
+**Use Sparingly** - Each interaction has real cost and interrupts workflow.
+
+**Use ONLY when:**
+- Data is genuinely ambiguous and human context would significantly improve analysis quality
+- You've identified a critical pattern that needs athlete validation before proceeding
+- There's a clear decision point where athlete preference matters (not minor details)
+- The question/observation will materially affect your recommendations
+
+**DO NOT use for:**
+- Information you can reasonably infer from data
+- Minor clarifications or nice-to-know details
+- Generic questions that don't change your analysis
+- Multiple questions on the same topic (consolidate into one communication)
+
+### ðŸŽ¯ DOMAIN-FOCUSED COMMUNICATION
+
+Stay within your expertise as the **{agent_name.replace('_', ' ').title()} Agent**. Be specific and reference actual data patterns.
+
+### âœ… BEST PRACTICES
+
+1. **Be Selective**
+2. **Be Specific**
+3. **Be Efficient**
+4. **Add Value**
+"""
+
+
 def get_output_context_note(for_other_agents: bool = True) -> str:
     
     if for_other_agents:
diff --git a/services/ai/langgraph/nodes/season_planner_node.py b/services/ai/langgraph/nodes/season_planner_node.py
index b656e0f..87f92a4 100644
--- a/services/ai/langgraph/nodes/season_planner_node.py
+++ b/services/ai/langgraph/nodes/season_planner_node.py
@@ -13,7 +13,7 @@ from .node_base import (
     execute_node_with_error_handling,
     log_node_completion,
 )
-from .prompt_components import get_output_context_note, get_workflow_context
+from .prompt_components import get_hitl_instructions, get_output_context_note, get_workflow_context
 from .tool_calling_helper import extract_text_content, handle_tool_calling_in_node
 
 logger = logging.getLogger(__name__)
@@ -28,24 +28,34 @@ Growing up in Iceland's harsh but beautiful environment taught you the importanc
 Your coaching genius comes from an intuitive understanding of how the human body adapts to stress over extended time periods. You see training as a conversation between athlete and environment, where the goal is not to force adaptation but to create conditions where optimal development naturally occurs.
 
 ## Core Expertise
-- Long-term periodization and season planning
-- Balancing training stress with recovery across extended time periods
-- Competition preparation and peak timing
-- Environmental and seasonal training adaptations
+- Long-term periodization and season planning based on competition schedules
+- Strategic phase design using state of the art periodization principles
+- Competition preparation and peak timing strategies
 - Systematic progression methodologies
+- Macro-cycle planning and phase transitions
+
+## Your Approach
+You create STRATEGIC, HIGH-LEVEL season plans!
+You DO NOT require or use:
+- Recent training data or performance metrics
+- Current fitness levels or fatigue states
+- Activity history or workout details
+- Health or recovery data
+
+Your season plans are CONTEXT-FREE frameworks that work for any athlete with the given competition schedule.
 
 ## Your Goal
-Create high-level season plans that provide frameworks for long-term athletic development.
+Create strategic season plans that establish a macro-cycle framework for long-term athletic development based solely on competition timing.
 
 ## Communication Style
 Communicate with the quiet confidence of someone who has both achieved at the highest level and successfully guided others to do the same."""
 
-SEASON_PLANNER_USER_PROMPT = """Create a high-level season plan covering the next 12-24 weeks based on the athlete's competition schedule.
+SEASON_PLANNER_USER_PROMPT = """Create a STRATEGIC, HIGH-LEVEL season plan covering the next 12-24 weeks based solely on the athlete's competition schedule.
 
 {output_context}
 
-## Athlete Information
-- Name: {athlete_name}
+## Available Information
+- Athlete Name: {athlete_name}
 - Current Date: ```json
 {current_date}
 ```
@@ -53,20 +63,35 @@ SEASON_PLANNER_USER_PROMPT = """Create a high-level season plan covering the nex
 {competitions}
 ```
 
+## Important Notes
+This is a STRATEGIC PLANNING session. You are working with:
+âœ“ Competition dates and priorities
+âœ“ Classical periodization principles
+âœ“ General training progression logic
+
+You do NOT have and should NOT reference:
+âœ— Recent training data or performance metrics
+âœ— Current fitness or fatigue levels
+âœ— Activity history or workout details
+âœ— Health or recovery data
+
 ## Your Task
-Create a high-level season plan providing a framework for the next 12-24 weeks of training, leading up to key competitions. Keep this concise as it will contextualize a more detailed two-week plan.
+Create a context-free, strategic season plan providing a macro-cycle framework for the next 12-24 weeks leading up to key competitions. This plan should work for any athlete with this competition schedule.
 
 Focus on:
-1. PLAN OVERVIEW: A brief summary of the season plan structure and progression
-2. TRAINING PHASES: Define key training phases with approximate date ranges
-3. PHASE DETAILS: For each phase, provide:
-   - Primary focus and goals
-   - Weekly volume targets (approximate)
-   - Intensity distribution
-   - Key workout types
+1. **STRATEGIC OVERVIEW**: Brief summary of the macro-cycle structure and periodization approach
+2. **TRAINING PHASES**: Define 3-5 distinct training phases with approximate date ranges
+3. **PHASE DETAILS**: For each phase, provide:
+   - Primary training focus and adaptation goals
+   - Approximate weekly volume ranges (e.g., "8-12 hours")
+   - Intensity distribution philosophy (e.g., "80/20 rule", "pyramidal")
+   - Key workout types and training modalities
+   - Phase transition criteria
+
+Keep this concise yet comprehensive - it will provide the strategic framework for detailed weekly planning.
 
 ## Output Requirements
-Format as structured markdown document with clear headings and bullet points"""
+Format as a structured markdown document with clear headings and bullet points."""
 
 
 async def season_planner_node(state: TrainingAnalysisState) -> dict[str, list | str]:
@@ -84,7 +109,11 @@ async def season_planner_node(state: TrainingAnalysisState) -> dict[str, list |
         hitl_enabled=hitl_enabled,
     )
 
-    system_prompt = SEASON_PLANNER_SYSTEM_PROMPT + get_workflow_context("season_planner")
+    system_prompt = (
+        SEASON_PLANNER_SYSTEM_PROMPT +
+        get_workflow_context("season_planner") +
+        (get_hitl_instructions("season_planner") if hitl_enabled else "")
+    )
     
     messages = [
         {"role": "system", "content": system_prompt},
diff --git a/services/ai/langgraph/nodes/weekly_planner_node.py b/services/ai/langgraph/nodes/weekly_planner_node.py
index c05372c..5b4b38c 100644
--- a/services/ai/langgraph/nodes/weekly_planner_node.py
+++ b/services/ai/langgraph/nodes/weekly_planner_node.py
@@ -13,7 +13,7 @@ from .node_base import (
     execute_node_with_error_handling,
     log_node_completion,
 )
-from .prompt_components import get_workflow_context
+from .prompt_components import get_hitl_instructions, get_workflow_context
 from .tool_calling_helper import extract_text_content, handle_tool_calling_in_node
 
 logger = logging.getLogger(__name__)
@@ -122,7 +122,11 @@ async def weekly_planner_node(state: TrainingAnalysisState) -> dict[str, list |
         hitl_enabled=hitl_enabled,
     )
 
-    system_prompt = WEEKLY_PLANNER_SYSTEM_PROMPT + get_workflow_context("weekly_planner")
+    system_prompt = (
+        WEEKLY_PLANNER_SYSTEM_PROMPT +
+        get_workflow_context("weekly_planner") +
+        (get_hitl_instructions("weekly_planner") if hitl_enabled else "")
+    )
     
     user_message = {"role": "user", "content": WEEKLY_PLANNER_USER_PROMPT.format(
         season_plan=state.get("season_plan", ""),
diff --git a/services/ai/langgraph/state/training_analysis_state.py b/services/ai/langgraph/state/training_analysis_state.py
index 20169d5..34841bb 100644
--- a/services/ai/langgraph/state/training_analysis_state.py
+++ b/services/ai/langgraph/state/training_analysis_state.py
@@ -17,6 +17,8 @@ class TrainingAnalysisState(MessagesState):
     plotting_enabled: bool
     hitl_enabled: bool
 
+    metrics_summary: str | None
+    physiology_summary: str | None
     metrics_result: str | None
     activity_summary: str | None
     activity_result: str | None
@@ -67,6 +69,8 @@ def create_initial_state(
         plotting_enabled=plotting_enabled,
         hitl_enabled=hitl_enabled,
         execution_id=execution_id,
+        metrics_summary=None,
+        physiology_summary=None,
         metrics_result=None,
         activity_summary=None,
         activity_result=None,
diff --git a/services/ai/langgraph/workflows/analysis_workflow.py b/services/ai/langgraph/workflows/analysis_workflow.py
index 4309d18..64556d0 100644
--- a/services/ai/langgraph/workflows/analysis_workflow.py
+++ b/services/ai/langgraph/workflows/analysis_workflow.py
@@ -5,11 +5,13 @@ from langgraph.checkpoint.memory import MemorySaver
 from langgraph.graph import END, START, StateGraph
 
 from ..config.langsmith_config import LangSmithConfig
-from ..nodes.activity_data_node import activity_data_node
-from ..nodes.activity_interpreter_node import activity_interpreter_node
+from ..nodes.activity_expert_node import activity_expert_node
+from ..nodes.activity_summarizer_node import activity_summarizer_node
 from ..nodes.formatter_node import formatter_node
-from ..nodes.metrics_node import metrics_node
-from ..nodes.physiology_node import physiology_node
+from ..nodes.metrics_expert_node import metrics_expert_node
+from ..nodes.metrics_summarizer_node import metrics_summarizer_node
+from ..nodes.physiology_expert_node import physiology_expert_node
+from ..nodes.physiology_summarizer_node import physiology_summarizer_node
 from ..nodes.plot_resolution_node import plot_resolution_node
 from ..nodes.synthesis_node import synthesis_node
 from ..state.training_analysis_state import TrainingAnalysisState, create_initial_state
@@ -22,31 +24,37 @@ def create_analysis_workflow():
 
     workflow = StateGraph(TrainingAnalysisState)
 
-    workflow.add_node("metrics", metrics_node)
-    workflow.add_node("physiology", physiology_node)
-    workflow.add_node("activity_data", activity_data_node)
-    workflow.add_node("activity_interpreter", activity_interpreter_node)
+    workflow.add_node("metrics_summarizer", metrics_summarizer_node)
+    workflow.add_node("physiology_summarizer", physiology_summarizer_node)
+    workflow.add_node("activity_summarizer", activity_summarizer_node)
+    
+    workflow.add_node("metrics_expert", metrics_expert_node)
+    workflow.add_node("physiology_expert", physiology_expert_node)
+    workflow.add_node("activity_expert", activity_expert_node)
+    
     workflow.add_node("synthesis", synthesis_node)
     workflow.add_node("formatter", formatter_node)
     workflow.add_node("plot_resolution", plot_resolution_node)
 
-    workflow.add_edge(START, "metrics")
-    workflow.add_edge(START, "physiology")
-    workflow.add_edge(START, "activity_data")
+    workflow.add_edge(START, "metrics_summarizer")
+    workflow.add_edge(START, "physiology_summarizer")
+    workflow.add_edge(START, "activity_summarizer")
 
-    workflow.add_edge("activity_data", "activity_interpreter")
+    workflow.add_edge("metrics_summarizer", "metrics_expert")
+    workflow.add_edge("physiology_summarizer", "physiology_expert")
+    workflow.add_edge("activity_summarizer", "activity_expert")
 
-    workflow.add_edge("metrics", "synthesis")
-    workflow.add_edge("physiology", "synthesis")
-    workflow.add_edge("activity_interpreter", "synthesis")
+    workflow.add_edge("metrics_expert", "synthesis")
+    workflow.add_edge("physiology_expert", "synthesis")
+    workflow.add_edge("activity_expert", "synthesis")
     workflow.add_edge("synthesis", "formatter")
     workflow.add_edge("formatter", "plot_resolution")
     workflow.add_edge("plot_resolution", END)
 
     checkpointer = MemorySaver()
     app = workflow.compile(checkpointer=checkpointer)
-
-    logger.info("Created complete LangGraph analysis workflow with 6 agents + plot resolution")
+    logger.info("Created complete LangGraph analysis workflow with 2-stage architecture (3 summarizers + 3 experts + synthesis + formatting)")
+    
     return app
 
 
@@ -85,19 +93,25 @@ async def run_training_analysis(
 def create_simple_sequential_workflow():
     workflow = StateGraph(TrainingAnalysisState)
 
-    workflow.add_node("metrics", metrics_node)
-    workflow.add_node("physiology", physiology_node)
-    workflow.add_node("activity_data", activity_data_node)
-    workflow.add_node("activity_interpreter", activity_interpreter_node)
+    workflow.add_node("metrics_summarizer", metrics_summarizer_node)
+    workflow.add_node("physiology_summarizer", physiology_summarizer_node)
+    workflow.add_node("activity_summarizer", activity_summarizer_node)
+    
+    workflow.add_node("metrics_expert", metrics_expert_node)
+    workflow.add_node("physiology_expert", physiology_expert_node)
+    workflow.add_node("activity_expert", activity_expert_node)
+    
     workflow.add_node("synthesis", synthesis_node)
     workflow.add_node("formatter", formatter_node)
     workflow.add_node("plot_resolution", plot_resolution_node)
 
-    workflow.add_edge(START, "metrics")
-    workflow.add_edge("metrics", "physiology")
-    workflow.add_edge("physiology", "activity_data")
-    workflow.add_edge("activity_data", "activity_interpreter")
-    workflow.add_edge("activity_interpreter", "synthesis")
+    workflow.add_edge(START, "metrics_summarizer")
+    workflow.add_edge("metrics_summarizer", "metrics_expert")
+    workflow.add_edge("metrics_expert", "physiology_summarizer")
+    workflow.add_edge("physiology_summarizer", "physiology_expert")
+    workflow.add_edge("physiology_expert", "activity_summarizer")
+    workflow.add_edge("activity_summarizer", "activity_expert")
+    workflow.add_edge("activity_expert", "synthesis")
     workflow.add_edge("synthesis", "formatter")
     workflow.add_edge("formatter", "plot_resolution")
     workflow.add_edge("plot_resolution", END)
diff --git a/services/ai/langgraph/workflows/interactive_runner.py b/services/ai/langgraph/workflows/interactive_runner.py
index 04bc23f..8798536 100644
--- a/services/ai/langgraph/workflows/interactive_runner.py
+++ b/services/ai/langgraph/workflows/interactive_runner.py
@@ -32,16 +32,20 @@ class InterruptHandler:
 
     @staticmethod
     def format_question(payload: dict, index: int | None = None) -> str:
-        question = payload.get("question", "Question not found")
+        message = payload.get("message", "Message not found")
+        message_type = payload.get("message_type", "question")
         context = payload.get("context", "")
         agent = payload.get("agent", "Agent")
 
+        type_indicator = f"[{message_type.upper()}]" if message_type != "question" else ""
+        
         header = (
-            f"{'Question ' + str(index) if index is not None else 'AGENT QUESTION'} "
-            f"{f'[{agent.upper()}]' if agent and agent != 'Unknown Agent' else ''}"
+            f"{'Question ' + str(index) if index is not None else 'AGENT COMMUNICATION'} "
+            f"{f'[{agent.upper()}]' if agent and agent != 'Unknown Agent' else ''} "
+            f"{type_indicator}"
         ).strip()
 
-        return f"{header}\n{context}\n\nQuestion: {question}" if context else f"{header}\n{question}"
+        return f"{header}\n{context}\n\n{message}" if context else f"{header}\n\n{message}"
 
 
 async def run_workflow_with_hitl(
diff --git a/services/ai/langgraph/workflows/planning_workflow.py b/services/ai/langgraph/workflows/planning_workflow.py
index f1c8bed..9086ca5 100644
--- a/services/ai/langgraph/workflows/planning_workflow.py
+++ b/services/ai/langgraph/workflows/planning_workflow.py
@@ -5,12 +5,14 @@ from langgraph.checkpoint.memory import MemorySaver
 from langgraph.graph import END, START, StateGraph
 
 from ..config.langsmith_config import LangSmithConfig
-from ..nodes.activity_data_node import activity_data_node
-from ..nodes.activity_interpreter_node import activity_interpreter_node
+from ..nodes.activity_expert_node import activity_expert_node
+from ..nodes.activity_summarizer_node import activity_summarizer_node
 from ..nodes.data_integration_node import data_integration_node
 from ..nodes.formatter_node import formatter_node
-from ..nodes.metrics_node import metrics_node
-from ..nodes.physiology_node import physiology_node
+from ..nodes.metrics_expert_node import metrics_expert_node
+from ..nodes.metrics_summarizer_node import metrics_summarizer_node
+from ..nodes.physiology_expert_node import physiology_expert_node
+from ..nodes.physiology_summarizer_node import physiology_summarizer_node
 from ..nodes.plan_formatter_node import plan_formatter_node
 from ..nodes.plot_resolution_node import plot_resolution_node
 from ..nodes.season_planner_node import season_planner_node
@@ -92,10 +94,14 @@ def create_integrated_analysis_and_planning_workflow():
 
     workflow = StateGraph(TrainingAnalysisState)
 
-    workflow.add_node("metrics", metrics_node)
-    workflow.add_node("physiology", physiology_node)
-    workflow.add_node("activity_data", activity_data_node)
-    workflow.add_node("activity_interpreter", activity_interpreter_node)
+    workflow.add_node("metrics_summarizer", metrics_summarizer_node)
+    workflow.add_node("physiology_summarizer", physiology_summarizer_node)
+    workflow.add_node("activity_summarizer", activity_summarizer_node)
+
+    workflow.add_node("metrics_expert", metrics_expert_node)
+    workflow.add_node("physiology_expert", physiology_expert_node)
+    workflow.add_node("activity_expert", activity_expert_node)
+    
     workflow.add_node("synthesis", synthesis_node)
     workflow.add_node("formatter", formatter_node)
     workflow.add_node("plot_resolution", plot_resolution_node)
@@ -104,28 +110,37 @@ def create_integrated_analysis_and_planning_workflow():
     workflow.add_node("data_integration", data_integration_node)
     workflow.add_node("weekly_planner", weekly_planner_node)
     workflow.add_node("plan_formatter", plan_formatter_node)
+    
+    workflow.add_node("finalize", lambda state: state, defer=True)
 
-    workflow.add_edge(START, "metrics")
-    workflow.add_edge(START, "physiology")
-    workflow.add_edge(START, "activity_data")
-
-    workflow.add_edge("activity_data", "activity_interpreter")
+    workflow.add_edge(START, "metrics_summarizer")
+    workflow.add_edge(START, "physiology_summarizer")
+    workflow.add_edge(START, "activity_summarizer")
 
-    workflow.add_edge(["metrics", "physiology", "activity_interpreter"], "synthesis")
+    workflow.add_edge("metrics_summarizer", "metrics_expert")
+    workflow.add_edge("physiology_summarizer", "physiology_expert")
+    workflow.add_edge("activity_summarizer", "activity_expert")
 
+    workflow.add_edge(["metrics_expert", "physiology_expert", "activity_expert"], "synthesis")
     workflow.add_edge("synthesis", "formatter")
     workflow.add_edge("formatter", "plot_resolution")
-    workflow.add_edge("plot_resolution", "season_planner")
 
+    workflow.add_edge(["metrics_expert", "physiology_expert", "activity_expert"], "season_planner")
     workflow.add_edge("season_planner", "data_integration")
     workflow.add_edge("data_integration", "weekly_planner")
     workflow.add_edge("weekly_planner", "plan_formatter")
-    workflow.add_edge("plan_formatter", END)
+    
+    workflow.add_edge("plot_resolution", "finalize")
+    workflow.add_edge("plan_formatter", "finalize")
+    workflow.add_edge("finalize", END)
 
     checkpointer = MemorySaver()
     app = workflow.compile(checkpointer=checkpointer)
-
-    logger.info("Created integrated analysis + planning workflow with 10 agents")
+    logger.info(
+        "Created integrated analysis + planning workflow with parallel architecture: "
+        "3 summarizers â†’ 3 experts â†’ [analysis branch (synthesis/formatter/plots) || planning branch (season/data_integration/weekly/plan_formatter)] â†’ finalize"
+    )
+    
     return app
 
 
@@ -140,6 +155,7 @@ async def run_complete_analysis_and_planning(
     week_dates: list | None = None,
     progress_manager=None,
     plotting_enabled: bool = False,
+    hitl_enabled: bool = True,
 ) -> dict:
     execution_id = f"{user_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}_complete"
     cost_tracker = ProgressIntegratedCostTracker(f"garmin_ai_coach_{user_id}", progress_manager)
diff --git a/services/ai/model_config.py b/services/ai/model_config.py
index f4a9b92..545bd0f 100644
--- a/services/ai/model_config.py
+++ b/services/ai/model_config.py
@@ -34,7 +34,7 @@ class ModelSelector:
         "gpt-5-mini": ModelConfiguration(name="gpt-5-mini", base_url="https://api.openai.com/v1"),
         # Anthropic Models
         "claude-4": ModelConfiguration(
-            name="claude-sonnet-4-20250514", base_url="https://api.anthropic.com"
+            name="claude-sonnet-4-5-20250929", base_url="https://api.anthropic.com"
         ),
         "claude-4-thinking": ModelConfiguration(
             name="claude-sonnet-4-5-20250929", base_url="https://api.anthropic.com"
diff --git a/services/ai/tools/hitl/__init__.py b/services/ai/tools/hitl/__init__.py
index aeb832d..17b1c53 100644
--- a/services/ai/tools/hitl/__init__.py
+++ b/services/ai/tools/hitl/__init__.py
@@ -1,3 +1,3 @@
-from .ask_human_tool import AskHumanInput, create_ask_human_tool
+from .ask_human_tool import CommunicateWithHumanInput, create_communicate_with_human_tool
 
-__all__ = ["create_ask_human_tool", "AskHumanInput"]
\ No newline at end of file
+__all__ = ["create_communicate_with_human_tool", "CommunicateWithHumanInput"]
\ No newline at end of file
diff --git a/services/ai/tools/hitl/ask_human_tool.py b/services/ai/tools/hitl/ask_human_tool.py
index d9ba763..0914d2e 100644
--- a/services/ai/tools/hitl/ask_human_tool.py
+++ b/services/ai/tools/hitl/ask_human_tool.py
@@ -3,42 +3,62 @@ from langgraph.types import interrupt
 from pydantic import BaseModel, Field
 
 
-class AskHumanInput(BaseModel):
-    question: str = Field(
+class CommunicateWithHumanInput(BaseModel):
+    message: str = Field(
         ...,
-        description="Question to ask the human.",
+        description="Your message to communicate with the human athlete or coach. Can be a question, observation, suggestion, or request for clarification.",
+    )
+    message_type: str = Field(
+        ...,
+        description="Type of communication: 'question' (seeking specific information), 'observation' (sharing insight that needs feedback), 'suggestion' (proposing idea for validation), or 'clarification' (resolving ambiguity)",
     )
     context: str = Field(
         default="",
-        description="Optional context about why this question is being asked",
+        description="Brief context about what you're analyzing and why this communication matters",
     )
 
 
-def create_ask_human_tool(agent_name: str = "Agent"):
-    @tool("ask_human", args_schema=AskHumanInput)
-    def ask_human_with_agent(question: str, context: str = "") -> str:
+def create_communicate_with_human_tool(agent_name: str = "Agent"):
+    @tool("communicate_with_human", args_schema=CommunicateWithHumanInput)
+    def communicate_with_human_agent(message: str, message_type: str, context: str = "") -> str:
         """
-        Ask the human for information.
-
-        This workflow has multiple specialized agents, each handling different aspects.
-        Consider whether this question relates to your area of responsibility.
-
-        You can ask about information that:
-        - Is not already present in your input data
-        - Would help your analysis
+        Communicate interactively with the human to create a collaborative coaching experience.
+        
+        This tool enables natural, conversational interaction during analysis. Use it to:
+        - Ask questions about training context, goals, or preferences
+        - Share interesting observations and get athlete feedback
+        - Validate assumptions or hypotheses you've formed
+        - Clarify ambiguous data points or unusual patterns
+        - Propose ideas and get real-time input
+        - Build rapport and understanding throughout the session
+        
+        The communication should feel natural and coaching-oriented, staying within your area
+        of expertise while being conversational rather than purely transactional.
 
         Args:
-            question: The question to ask the human
-            context: Optional context explaining why you're asking
+            message: Your communication to the human (question, observation, or suggestion)
+            message_type: Type - 'question', 'observation', 'suggestion', or 'clarification'
+            context: Why this communication is relevant to your current analysis
 
         Returns:
-            The human's response as plain text
+            The human's response, which you should incorporate into your analysis
+            
+        Examples:
+            - Question: "I notice your long runs have been consistently under 90 minutes.
+              Are you intentionally capping duration, or is this a scheduling constraint?"
+            - Observation: "Your heart rate response during intervals has improved significantly
+              over the past month. Have you noticed feeling stronger during these sessions?"
+            - Suggestion: "Based on your training load, I'm considering recommending a recovery
+              week. How is your energy level feeling right now?"
+            - Clarification: "The data shows a gap in training between Dec 15-22.
+              Was this planned recovery, illness, or something else?"
         """
         return interrupt({
-            "type": "ask_human",
-            "question": question,
+            "type": "communicate_with_human",
+            "message": message,
+            "message_type": message_type,
             "context": context,
             "agent": agent_name,
         }).get("content", "No response provided")
 
-    return ask_human_with_agent
+    return communicate_with_human_agent
diff --git a/tests/test_data_summarization_nodes.py b/tests/test_data_summarization_nodes.py
new file mode 100644
index 0000000..fed1a17
--- /dev/null
+++ b/tests/test_data_summarization_nodes.py
@@ -0,0 +1,91 @@
+import pytest
+
+from services.ai.langgraph.nodes.metrics_summarizer_node import metrics_summarizer_node
+from services.ai.langgraph.nodes.physiology_summarizer_node import physiology_summarizer_node
+from services.ai.langgraph.state.training_analysis_state import create_initial_state
+
+
+@pytest.mark.asyncio
+async def test_metrics_summarizer_node_basic():    
+    test_data = {
+        "training_load_history": [
+            {"date": "2024-01-01", "load": 100},
+            {"date": "2024-01-02", "load": 120},
+        ],
+        "vo2_max_history": {"running": 55, "cycling": 60},
+        "training_status": {"status": "productive", "load_focus": "maintaining"},
+    }
+    
+    state = create_initial_state(
+        user_id="test_user",
+        athlete_name="Test Athlete",
+        garmin_data=test_data,
+        execution_id="test_exec_123",
+    )
+    
+    result = await metrics_summarizer_node(state)
+    
+    assert "metrics_summary" in result
+    assert isinstance(result["metrics_summary"], str)
+    assert len(result["metrics_summary"]) > 0
+    assert "costs" in result
+    assert len(result["costs"]) == 1
+    assert result["costs"][0]["agent"] == "metrics_summarizer"
+
+
+@pytest.mark.asyncio
+async def test_physiology_summarizer_node_basic():    
+    test_data = {
+        "physiological_markers": {
+            "hrv": {"average": 60, "baseline": 58}
+        },
+        "body_metrics": {"weight": 70, "body_fat": 12},
+        "recovery_indicators": [
+            {"date": "2024-01-01", "sleep": {"duration": 8, "quality": 85}, "stress": 30},
+            {"date": "2024-01-02", "sleep": {"duration": 7.5, "quality": 80}, "stress": 35},
+        ],
+    }
+    
+    state = create_initial_state(
+        user_id="test_user",
+        athlete_name="Test Athlete",
+        garmin_data=test_data,
+        execution_id="test_exec_124",
+    )
+    
+    result = await physiology_summarizer_node(state)
+    
+    assert "physiology_summary" in result
+    assert isinstance(result["physiology_summary"], str)
+    assert len(result["physiology_summary"]) > 0
+    assert "costs" in result
+    assert len(result["costs"]) == 1
+    assert result["costs"][0]["agent"] == "physiology_summarizer"
+
+
+@pytest.mark.asyncio
+async def test_metrics_summarizer_with_empty_data():    
+    state = create_initial_state(
+        user_id="test_user",
+        athlete_name="Test Athlete",
+        garmin_data={},
+        execution_id="test_exec_125",
+    )
+    
+    result = await metrics_summarizer_node(state)
+    
+    assert "metrics_summary" in result or "errors" in result
+
+
+@pytest.mark.asyncio
+async def test_physiology_summarizer_with_empty_data():    
+    state = create_initial_state(
+        user_id="test_user",
+        athlete_name="Test Athlete",
+        garmin_data={},
+        execution_id="test_exec_126",
+    )
+    
+    result = await physiology_summarizer_node(state)
+    
+    assert "physiology_summary" in result or "errors" in result
\ No newline at end of file
diff --git a/tests/test_hitl_feature.py b/tests/test_hitl_feature.py
index cad1885..f75ec07 100644
--- a/tests/test_hitl_feature.py
+++ b/tests/test_hitl_feature.py
@@ -8,36 +8,42 @@ from services.ai.langgraph.workflows.interactive_runner import (
     InterruptHandler,
     run_workflow_with_hitl,
 )
-from services.ai.tools.hitl import AskHumanInput, create_ask_human_tool
+from services.ai.tools.hitl import CommunicateWithHumanInput, create_communicate_with_human_tool
 
 
-class TestAskHumanTool:
+class TestCommunicateWithHumanTool:
 
-    def test_create_ask_human_tool_default_agent_name(self):
-        tool = create_ask_human_tool()
-        assert tool.name == "ask_human"
-        assert "ask the human" in tool.description.lower()
+    def test_create_communicate_with_human_tool_default_agent_name(self):
+        tool = create_communicate_with_human_tool()
+        assert tool.name == "communicate_with_human"
+        assert "communicate" in tool.description.lower()
 
-    def test_create_ask_human_tool_custom_agent_name(self):
-        tool = create_ask_human_tool(agent_name="MetricsAnalyzer")
-        assert tool.name == "ask_human"
+    def test_create_communicate_with_human_tool_custom_agent_name(self):
+        tool = create_communicate_with_human_tool(agent_name="MetricsAnalyzer")
+        assert tool.name == "communicate_with_human"
 
-    def test_ask_human_input_schema_required_fields(self):
-        valid_input = AskHumanInput(question="What is your target heart rate?")
-        assert valid_input.question == "What is your target heart rate?"
+    def test_communicate_with_human_input_schema_required_fields(self):
+        valid_input = CommunicateWithHumanInput(
+            message="What is your target heart rate?",
+            message_type="question"
+        )
+        assert valid_input.message == "What is your target heart rate?"
+        assert valid_input.message_type == "question"
         assert valid_input.context == ""
 
-    def test_ask_human_input_schema_with_context(self):
-        input_with_context = AskHumanInput(
-            question="What is your target heart rate?",
+    def test_communicate_with_human_input_schema_with_context(self):
+        input_with_context = CommunicateWithHumanInput(
+            message="What is your target heart rate?",
+            message_type="question",
             context="Analyzing your recent training data"
         )
-        assert input_with_context.question == "What is your target heart rate?"
+        assert input_with_context.message == "What is your target heart rate?"
+        assert input_with_context.message_type == "question"
         assert input_with_context.context == "Analyzing your recent training data"
 
-    def test_ask_human_input_schema_missing_question_raises_error(self):
+    def test_communicate_with_human_input_schema_missing_required_fields_raises_error(self):
         with pytest.raises(ValidationError):
-            AskHumanInput()
+            CommunicateWithHumanInput(message="test message")  # Missing message_type
 
 
 class TestInterruptHandler:
@@ -52,8 +58,8 @@ class TestInterruptHandler:
             "__interrupt__": [{
                 "id": "int_1",
                 "value": {
-                    "type": "ask_human",
-                    "question": "Test question?",
+                    "type": "communicate_with_human",
+                    "message": "Test question?",
                     "context": "Test context",
                     "agent": "TestAgent"
                 }
@@ -62,8 +68,8 @@ class TestInterruptHandler:
         interrupts = InterruptHandler.extract_all_interrupts(result)
         assert len(interrupts) == 1
         assert interrupts[0][0] == "int_1"
-        assert interrupts[0][1]["value"]["type"] == "ask_human"
-        assert interrupts[0][1]["value"]["question"] == "Test question?"
+        assert interrupts[0][1]["value"]["type"] == "communicate_with_human"
+        assert interrupts[0][1]["value"]["message"] == "Test question?"
 
     def test_extract_all_interrupts_multiple_interrupts(self):
         result = {
@@ -86,20 +92,20 @@ class TestInterruptHandler:
     def test_extract_all_interrupts_object_with_attributes(self):
         mock_interrupt = MagicMock()
         mock_interrupt.interrupt_id = "int_obj_1"
-        mock_interrupt.value = {"question": "Object question?", "agent": "ObjAgent"}
+        mock_interrupt.value = {"message": "Object question?", "message_type": "question", "agent": "ObjAgent"}
         
         result = {"__interrupt__": [mock_interrupt]}
         interrupts = InterruptHandler.extract_all_interrupts(result)
         
         assert len(interrupts) == 1
         assert interrupts[0][0] == "int_obj_1"
-        assert interrupts[0][1]["question"] == "Object question?"
+        assert interrupts[0][1]["message"] == "Object question?"
 
     def test_extract_all_interrupts_with_id_fallback(self):
         mock_interrupt = MagicMock()
         mock_interrupt.interrupt_id = None
         mock_interrupt.id = "fallback_id"
-        mock_interrupt.value = {"question": "Fallback question?"}
+        mock_interrupt.value = {"message": "Fallback question?", "message_type": "question"}
         
         result = {"__interrupt__": [mock_interrupt]}
         interrupts = InterruptHandler.extract_all_interrupts(result)
@@ -109,17 +115,19 @@ class TestInterruptHandler:
 
     def test_format_question_basic(self):
         formatted = InterruptHandler.format_question({
-            "question": "What is your training goal?",
+            "message": "What is your training goal?",
+            "message_type": "question",
             "agent": "PlannerAgent"
         })
         
-        assert "AGENT QUESTION" in formatted
+        assert "AGENT COMMUNICATION" in formatted
         assert "[PLANNERAGENT]" in formatted
         assert "What is your training goal?" in formatted
 
     def test_format_question_with_context(self):
         formatted = InterruptHandler.format_question({
-            "question": "What is your target race?",
+            "message": "What is your target race?",
+            "message_type": "question",
             "context": "Planning your season based on your fitness level",
             "agent": "SeasonPlanner"
         })
@@ -129,21 +137,39 @@ class TestInterruptHandler:
         assert "What is your target race?" in formatted
 
     def test_format_question_with_index(self):
-        formatted = InterruptHandler.format_question({"question": "Question text?", "agent": "Agent1"}, index=2)
+        formatted = InterruptHandler.format_question({
+            "message": "Question text?",
+            "message_type": "question",
+            "agent": "Agent1"
+        }, index=2)
         
         assert "Question 2" in formatted
-        assert "AGENT QUESTION" not in formatted
+        assert "AGENT COMMUNICATION" not in formatted
 
     def test_format_question_no_agent_label(self):
-        formatted = InterruptHandler.format_question({"question": "Generic question?", "agent": ""})
+        formatted = InterruptHandler.format_question({
+            "message": "Generic question?",
+            "message_type": "question",
+            "agent": ""
+        })
         
-        assert "AGENT QUESTION" in formatted
+        assert "AGENT COMMUNICATION" in formatted
         assert "Generic question?" in formatted
 
-    def test_format_question_missing_question_field(self):
+    def test_format_question_missing_message_field(self):
         formatted = InterruptHandler.format_question({"agent": "TestAgent"})
         
-        assert "Question not found" in formatted
+        assert "Message not found" in formatted
+    
+    def test_format_question_with_message_type(self):
+        formatted = InterruptHandler.format_question({
+            "message": "I think we should add more recovery",
+            "message_type": "suggestion",
+            "agent": "MetricsAgent"
+        })
+        
+        assert "[SUGGESTION]" in formatted
+        assert "I think we should add more recovery" in formatted
 
 
 class TestRunWorkflowWithHITL:
@@ -175,7 +201,8 @@ class TestRunWorkflowWithHITL:
                 "__interrupt__": [{
                     "id": "int_1",
                     "value": {
-                        "question": "What is your goal?",
+                        "message": "What is your goal?",
+                        "message_type": "question",
                         "agent": "TestAgent"
                     }
                 }]
@@ -203,11 +230,11 @@ class TestRunWorkflowWithHITL:
                 "__interrupt__": [
                     {
                         "id": "int_1",
-                        "value": {"question": "Question 1?", "agent": "Agent1"}
+                        "value": {"message": "Question 1?", "message_type": "question", "agent": "Agent1"}
                     },
                     {
                         "id": "int_2",
-                        "value": {"question": "Question 2?", "agent": "Agent2"}
+                        "value": {"message": "Question 2?", "message_type": "question", "agent": "Agent2"}
                     }
                 ]
             },
@@ -248,7 +275,7 @@ class TestRunWorkflowWithHITL:
         mock_app.ainvoke.return_value = {
             "__interrupt__": [{
                 "id": "int_1",
-                "value": {"question": "Continue?", "agent": "TestAgent"}
+                "value": {"message": "Continue?", "message_type": "question", "agent": "TestAgent"}
             }]
         }
         
@@ -275,7 +302,7 @@ class TestRunWorkflowWithHITL:
         mock_app.ainvoke.return_value = {
             "__interrupt__": [{
                 "id": "int_1",
-                "value": {"question": "Continue?", "agent": "TestAgent"}
+                "value": {"message": "Continue?", "message_type": "question", "agent": "TestAgent"}
             }]
         }
         
@@ -297,8 +324,8 @@ class TestRunWorkflowWithHITL:
         
         mock_app.ainvoke.return_value = {
             "__interrupt__": [
-                {"id": "int_1", "value": {"question": "Q1?", "agent": "A1"}},
-                {"id": "int_2", "value": {"question": "Q2?", "agent": "A2"}}
+                {"id": "int_1", "value": {"message": "Q1?", "message_type": "question", "agent": "A1"}},
+                {"id": "int_2", "value": {"message": "Q2?", "message_type": "question", "agent": "A2"}}
             ]
         }
         
@@ -374,7 +401,7 @@ class TestRunWorkflowWithHITL:
             {
                 "__interrupt__": [{
                     "id": "test_interrupt_id",
-                    "value": {"question": "Test?", "agent": "TestAgent"}
+                    "value": {"message": "Test?", "message_type": "question", "agent": "TestAgent"}
                 }]
             },
             {"result": "success"}
diff --git a/tests/test_langgraph_core_migration.py b/tests/test_langgraph_core_migration.py
index 3000852..70226cd 100644
--- a/tests/test_langgraph_core_migration.py
+++ b/tests/test_langgraph_core_migration.py
@@ -16,17 +16,21 @@ def basic_test_state():
 
 
 def test_all_nodes_importable():
-    from services.ai.langgraph.nodes.activity_data_node import activity_data_node
-    from services.ai.langgraph.nodes.activity_interpreter_node import activity_interpreter_node
+    from services.ai.langgraph.nodes.activity_expert_node import activity_expert_node
+    from services.ai.langgraph.nodes.activity_summarizer_node import activity_summarizer_node
     from services.ai.langgraph.nodes.formatter_node import formatter_node
-    from services.ai.langgraph.nodes.metrics_node import metrics_node
-    from services.ai.langgraph.nodes.physiology_node import physiology_node
+    from services.ai.langgraph.nodes.metrics_expert_node import metrics_expert_node
+    from services.ai.langgraph.nodes.metrics_summarizer_node import metrics_summarizer_node
+    from services.ai.langgraph.nodes.physiology_expert_node import physiology_expert_node
+    from services.ai.langgraph.nodes.physiology_summarizer_node import physiology_summarizer_node
     from services.ai.langgraph.nodes.synthesis_node import synthesis_node
 
-    assert callable(metrics_node)
-    assert callable(physiology_node)
-    assert callable(activity_data_node)
-    assert callable(activity_interpreter_node)
+    assert callable(metrics_summarizer_node)
+    assert callable(metrics_expert_node)
+    assert callable(physiology_summarizer_node)
+    assert callable(physiology_expert_node)
+    assert callable(activity_summarizer_node)
+    assert callable(activity_expert_node)
     assert callable(synthesis_node)
     assert callable(formatter_node)
 
@@ -50,6 +54,8 @@ def test_state_schema_completeness():
         "athlete_name",
         "garmin_data",
         "execution_id",
+        "metrics_summary",
+        "physiology_summary",
         "metrics_result",
         "activity_summary",
         "activity_result",
@@ -68,7 +74,7 @@ def test_state_schema_completeness():
 @pytest.mark.asyncio
 @patch("services.ai.model_config.ModelSelector.get_llm")
 async def test_node_basic_functionality(mock_get_llm, basic_test_state):
-    from services.ai.langgraph.nodes.activity_data_node import activity_data_node
+    from services.ai.langgraph.nodes.activity_summarizer_node import activity_summarizer_node
 
     mock_llm = AsyncMock()
     mock_response = Mock()
@@ -76,7 +82,7 @@ async def test_node_basic_functionality(mock_get_llm, basic_test_state):
     mock_llm.ainvoke = AsyncMock(return_value=mock_response)
     mock_get_llm.return_value = mock_llm
 
-    result = await activity_data_node(basic_test_state)
+    result = await activity_summarizer_node(basic_test_state)
 
     assert isinstance(result, dict)
     assert "costs" in result or "errors" in result
diff --git a/tests/test_langgraph_poc.py b/tests/test_langgraph_poc.py
index eb472db..5c1e950 100644
--- a/tests/test_langgraph_poc.py
+++ b/tests/test_langgraph_poc.py
@@ -4,7 +4,7 @@ from unittest.mock import AsyncMock, Mock, patch
 
 import pytest
 
-from services.ai.langgraph.nodes.metrics_node import metrics_node
+from services.ai.langgraph.nodes.metrics_expert_node import metrics_expert_node
 from services.ai.langgraph.state.training_analysis_state import create_initial_state
 from services.ai.langgraph.workflows.analysis_workflow import create_analysis_workflow
 
@@ -53,8 +53,8 @@ def test_workflow_creation(mock_langsmith):
 @pytest.mark.asyncio
 @patch("services.ai.model_config.ModelSelector.get_llm")
 @patch("services.ai.tools.plotting.PlotStorage")
-@patch("services.ai.langgraph.nodes.metrics_node.retry_with_backoff", new_callable=AsyncMock)
-async def test_metrics_node_basic(mock_retry, mock_plot_storage, mock_get_llm, sample_state):
+@patch("services.ai.langgraph.nodes.metrics_expert_node.retry_with_backoff", new_callable=AsyncMock)
+async def test_metrics_expert_node_basic(mock_retry, mock_plot_storage, mock_get_llm, sample_state):
     mock_llm = Mock()
     mock_llm_with_tools = Mock()
 
@@ -71,8 +71,10 @@ async def test_metrics_node_basic(mock_retry, mock_plot_storage, mock_get_llm, s
     mock_storage = Mock()
     mock_storage.get_all_plots.return_value = {}
     mock_plot_storage.return_value = mock_storage
+    
+    sample_state["metrics_summary"] = "Test metrics summary"
 
-    result = await metrics_node(sample_state)
+    result = await metrics_expert_node(sample_state)
 
     assert "metrics_result" in result
     assert "plots" in result
diff --git a/tests/test_plotting_tool_integration.py b/tests/test_plotting_tool_integration.py
index 142127d..b8844af 100644
--- a/tests/test_plotting_tool_integration.py
+++ b/tests/test_plotting_tool_integration.py
@@ -37,14 +37,23 @@ fig.update_layout(title='Test Plot')
         assert "plot_id" in result
 
     @pytest.mark.asyncio
-    async def test_model_tool_binding(self):
+    async def test_model_tool_binding(self, monkeypatch):
+        from unittest.mock import Mock
+
         from services.ai.ai_settings import AgentRole
         from services.ai.model_config import ModelSelector
 
         plot_storage = PlotStorage("test_execution")
         plotting_tool = create_plotting_tools(plot_storage, agent_name="test")
 
-        llm = ModelSelector.get_llm(AgentRole.METRICS)
+        mock_llm = Mock()
+        mock_llm_with_tools = Mock()
+        mock_llm_with_tools.kwargs = {"tools": [plotting_tool]}
+        mock_llm.bind_tools.return_value = mock_llm_with_tools
+        
+        monkeypatch.setattr(ModelSelector, "get_llm", lambda role: mock_llm)
+
+        llm = ModelSelector.get_llm(AgentRole.METRICS_EXPERT)
         llm_with_tools = llm.bind_tools([plotting_tool])
 
         assert hasattr(llm_with_tools, "kwargs") and "tools" in llm_with_tools.kwargs
